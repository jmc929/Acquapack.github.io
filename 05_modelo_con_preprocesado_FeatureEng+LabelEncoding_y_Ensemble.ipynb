{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNadtvmY26VFyT7P9elmCMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmc929/Acquapack.github.io/blob/main/05_modelo_con_preprocesado_FeatureEng%2BLabelEncoding_y_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Readme\n"
      ],
      "metadata": {
        "id": "FnA_N-eQY2ZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "se debe cambiar el entorno de ejecuci√≥n para que el programa corra de manera correcta, se le da en entorno de ejecucion, cambiar tipo de entorno de ejecuci√≥n se selecciona gpu t4 y guardar, luego podra correr el notebook\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "preprocesado FeatureEng:\n",
        "\n",
        "Porque realizamos Ingenier√≠a de Caracter√≠sticas (Feature Engineering) al crear manualmente la variable SCORE_PRIVILEGIOS sumando los lujos. Esto no estaba en los datos originales.\n",
        "\n",
        "+LabelEncoding:\n",
        "\n",
        "Porque para poder meter los datos a los 3 modelos a la vez, convertimos todo el texto a n√∫meros enteros (0, 1, 2...) usando LabelEncoder. (Si hubi√©ramos usado OneHot o Nativo, XGBoost o LightGBM habr√≠an fallado o tardado m√°s).\n",
        "\n",
        "y Ensemble:\n",
        "\n",
        "Porque la t√©cnica de modelado no es un algoritmo individual, sino un Ensamble de Votaci√≥n (Voting) que promedia las probabilidades de tres \"cerebros\" distintos, los cuales son catboost XGBoosty ligtGBM."
      ],
      "metadata": {
        "id": "0Coe_w_0YzYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion\n"
      ],
      "metadata": {
        "id": "yVWLdBhuOw51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos las 3 librer√≠as de potencia\n",
        "!pip install catboost xgboost lightgbm -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurar Kaggle\n",
        "data = {\"username\":\"josemiguelc1\",\"key\":\"1a8778db87047d4dc2602b6e2395bf36\"}\n",
        "with open('kaggle.json','w') as f: json.dump(data, f)\n",
        "!chmod 600 kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "print(\"üì• Descargando datos...\")\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -p /content/ --force\n",
        "!unzip -o -q udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
        "print(\"‚úÖ Entorno listo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geYlzw3-O1QH",
        "outputId": "c3a4f2bd-5ae3-4c34-e3c2-2a22592e233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hüì• Descargando datos...\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "100% 29.9M/29.9M [00:00<00:00, 1.27GB/s]\n",
            "‚úÖ Entorno listo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento Unificado (Label Encoding)"
      ],
      "metadata": {
        "id": "usSkgTsDO5_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "TARGET_COL = 'RENDIMIENTO_GLOBAL'\n",
        "ID_COL = 'ID'\n",
        "\n",
        "# Unir para Feature Engineering\n",
        "df_all = pd.concat([df_train.drop(columns=[TARGET_COL]), df_test], axis=0)\n",
        "\n",
        "# --- 1. FEATURE ENGINEERING (Las variables nuevas) ---\n",
        "cols_tiene = [c for c in df_all.columns if 'TIENE' in c]\n",
        "for col in cols_tiene:\n",
        "    df_all[col] = df_all[col].astype(str).str.lower().map({'si': 1, 'yes': 1, 'no': 0}).fillna(0)\n",
        "df_all['SCORE_PRIVILEGIOS'] = df_all[cols_tiene].sum(axis=1)\n",
        "\n",
        "# --- 2. CODIFICACI√ìN NUM√âRICA (LABEL ENCODING) ---\n",
        "# XGBoost y LightGBM odian el texto. Convertimos todo a n√∫meros.\n",
        "categorical_cols = df_all.select_dtypes(include=['object']).columns.tolist()\n",
        "if ID_COL in categorical_cols: categorical_cols.remove(ID_COL)\n",
        "\n",
        "print(\"‚öôÔ∏è Convirtiendo texto a n√∫meros...\")\n",
        "for col in categorical_cols:\n",
        "    df_all[col] = df_all[col].fillna(\"Missing\").astype(str)\n",
        "    le = LabelEncoder()\n",
        "    df_all[col] = le.fit_transform(df_all[col])\n",
        "\n",
        "# Rellenar num√©ricos restantes\n",
        "numeric_cols = df_all.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "for col in numeric_cols:\n",
        "    df_all[col] = df_all[col].fillna(-999)\n",
        "\n",
        "# Separar\n",
        "X = df_all.iloc[:len(df_train)].drop(columns=[ID_COL], errors='ignore')\n",
        "X_test_final = df_all.iloc[len(df_train):].drop(columns=[ID_COL], errors='ignore')\n",
        "y = df_train[TARGET_COL]\n",
        "\n",
        "# Codificar Target tambi√©n\n",
        "le_target = LabelEncoder()\n",
        "y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "print(f\"‚úÖ Datos listos. Clases: {le_target.classes_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9_YWhYfO870",
        "outputId": "251dc4d2-1fea-4016-a659-c468a02929da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Convirtiendo texto a n√∫meros...\n",
            "‚úÖ Datos listos. Clases: ['alto' 'bajo' 'medio-alto' 'medio-bajo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 1 - CatBoost (GPU)"
      ],
      "metadata": {
        "id": "6hlI5eHXO_ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinstalaci√≥n r√°pida para evitar el error de CUDA driver\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos (Usamos stratify para mantener proporciones)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "\n",
        "print(\"üêØ Entrenando Modelo 1: CatBoost (Modo GPU)...\")\n",
        "\n",
        "model_cat = CatBoostClassifier(\n",
        "    iterations=2500,\n",
        "    learning_rate=0.04,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=5,\n",
        "\n",
        "    # --- CONFIGURACI√ìN GPU ---\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    # -------------------------\n",
        "\n",
        "    # Nota: No ponemos 'cat_features' aqu√≠ porque en el Ensamble\n",
        "    # ya convertimos todo a n√∫meros (LabelEncoding) en la celda 2.\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='Accuracy',\n",
        "    random_seed=42,\n",
        "    verbose=500,\n",
        "    early_stopping_rounds=200\n",
        ")\n",
        "\n",
        "model_cat.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    use_best_model=True\n",
        ")\n",
        "\n",
        "# Guardamos PROBABILIDADES para el ensamble\n",
        "probs_cat = model_cat.predict_proba(X_test_final)\n",
        "print(\"‚úÖ CatBoost terminado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNKdgixkPCli",
        "outputId": "3e0b7d94-4750-4843-97ce-5d7ea25c7f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m149.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m425.0/425.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0müêØ Entrenando Modelo 1: CatBoost (Modo GPU)...\n",
            "0:\tlearn: 0.3802166\ttest: 0.3801588\tbest: 0.3801588 (0)\ttotal: 47.1ms\tremaining: 1m 57s\n",
            "500:\tlearn: 0.4377133\ttest: 0.4293526\tbest: 0.4293815 (490)\ttotal: 11s\tremaining: 43.8s\n",
            "1000:\tlearn: 0.4529471\ttest: 0.4323562\tbest: 0.4327413 (944)\ttotal: 21.3s\tremaining: 32s\n",
            "1500:\tlearn: 0.4653829\ttest: 0.4332034\tbest: 0.4336462 (1420)\ttotal: 34.9s\tremaining: 23.2s\n",
            "bestTest = 0.4337424789\n",
            "bestIteration = 1536\n",
            "Shrink model to first 1537 iterations.\n",
            "‚úÖ CatBoost terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 2 - XGBoost (GPU)"
      ],
      "metadata": {
        "id": "M2EerS0PPEOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"üöÄ Entrenando Modelo 2: XGBoost (Modo GPU)...\")\n",
        "\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=2500,    # Subimos iteraciones para igualar potencia\n",
        "    learning_rate=0.04,\n",
        "    max_depth=8,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "\n",
        "    # --- CONFIGURACI√ìN GPU ---\n",
        "    tree_method='hist',   # M√©todo histograma (el m√°s r√°pido)\n",
        "    device='cuda',        # Usar la GPU de Colab\n",
        "    # -------------------------\n",
        "\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_xgb.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=500\n",
        ")\n",
        "\n",
        "probs_xgb = model_xgb.predict_proba(X_test_final)\n",
        "print(\"‚úÖ XGBoost terminado.\")"
      ],
      "metadata": {
        "id": "B4DNV_2aPGuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbba603-d126-464d-cd5e-5c79e17100a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Entrenando Modelo 2: XGBoost (Modo GPU)...\n",
            "[0]\tvalidation_0-mlogloss:1.37980\n",
            "[500]\tvalidation_0-mlogloss:1.20014\n",
            "[902]\tvalidation_0-mlogloss:1.19912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [13:19:32] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ XGBoost terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo 3 - LightGBM (CPU Optimizado)"
      ],
      "metadata": {
        "id": "i8FZchAaPJu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "print(\"üí° Entrenando Modelo 3: LightGBM...\")\n",
        "model_lgb = LGBMClassifier(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31, # T√≠pico de LightGBM\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_lgb.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='multi_logloss',\n",
        "    callbacks=[\n",
        "        # LightGBM usa callbacks para verbose en versiones nuevas,\n",
        "        # si falla, simplemente quita el argumento callbacks\n",
        "    ]\n",
        ")\n",
        "\n",
        "probs_lgb = model_lgb.predict_proba(X_test_final)\n",
        "print(\"‚úÖ LightGBM terminado.\")"
      ],
      "metadata": {
        "id": "ozfRNsSWPLDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29eb1a97-7668-450a-f713-eb2db46e6ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí° Entrenando Modelo 3: LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1238\n",
            "[LightGBM] [Info] Number of data points in the train set: 588625, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.371992\n",
            "[LightGBM] [Info] Start training from score -1.387091\n",
            "[LightGBM] [Info] Start training from score -1.395032\n",
            "[LightGBM] [Info] Start training from score -1.391214\n",
            "‚úÖ LightGBM terminado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EL ENSAMBLE (Soft Voting)"
      ],
      "metadata": {
        "id": "CytyTK8KPOML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚öñÔ∏è Calculando el Ensamble (Promedio Ponderado)...\")\n",
        "\n",
        "# Podemos dar pesos. CatBoost y XGBoost suelen ser mejores, les damos m√°s peso.\n",
        "# Pesos: CatBoost (40%) + XGBoost (40%) + LightGBM (20%)\n",
        "final_probs = (probs_cat * 0.4) + (probs_xgb * 0.4) + (probs_lgb * 0.2)\n",
        "\n",
        "# Elegimos la clase con mayor probabilidad promedio\n",
        "final_preds_indices = np.argmax(final_probs, axis=1)\n",
        "final_preds_texto = le_target.inverse_transform(final_preds_indices)\n",
        "\n",
        "# Crear archivo\n",
        "if ID_COL in df_test.columns:\n",
        "    test_ids = df_test[ID_COL]\n",
        "else:\n",
        "    test_ids = df_test.index\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test_ids,\n",
        "    TARGET_COL: final_preds_texto\n",
        "})\n",
        "\n",
        "out_filename = \"submission_07_Ensemble_Voting.csv\"\n",
        "submission.to_csv(out_filename, index=False)\n",
        "print(f\"üíæ Archivo Final Generado: {out_filename}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vy7nSMfHPQPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e41b602-d4e2-455c-dde1-d896249216ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öñÔ∏è Calculando el Ensamble (Promedio Ponderado)...\n",
            "üíæ Archivo Final Generado: submission_07_Ensemble_Voting.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Subir\n"
      ],
      "metadata": {
        "id": "hejVvJSLPWyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"Notebook 07 - Ensemble (CatBoost + XGBoost + LightGBM)\"\n",
        "!kaggle competitions submit -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia -f {out_filename} -m \"{message}\"\n",
        "\n",
        "print(\"üèÜ ¬°Subida lista! Este deber√≠a ser tu mejor puntaje.\")"
      ],
      "metadata": {
        "id": "GTia8H-iPYL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fac7b6e-e5d9-45fd-d232-f74acc912f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.04M/4.04M [00:03<00:00, 1.31MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20252 - Pruebas Saber Pro ColombiaüèÜ ¬°Subida lista! Este deber√≠a ser tu mejor puntaje.\n"
          ]
        }
      ]
    }
  ]
}